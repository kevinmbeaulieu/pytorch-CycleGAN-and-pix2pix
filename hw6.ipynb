{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torchvision import datasets\n",
    "\n",
    "train_dataset = datasets.MNIST('datasets/', train=True, download=True)\n",
    "test_dataset = datasets.MNIST('datasets/', train=False, download=True)\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    train_dataset.data,\n",
    "    train_dataset.targets,\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    test_dataset.data,\n",
    "    test_dataset.targets,\n",
    ")\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [50000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def save_images(dataset, path_A, path_B):\n",
    "    os.makedirs(path_A, exist_ok=True)\n",
    "    os.makedirs(path_B, exist_ok=True)\n",
    "\n",
    "    def clear_directory(path):\n",
    "        files = glob.glob(path + '*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "    clear_directory(path_A)\n",
    "    clear_directory(path_B)\n",
    "\n",
    "    images = [\n",
    "        (Image.fromarray(image.numpy().astype('uint8')), int(label))\n",
    "        for image, label in dataset\n",
    "    ]\n",
    "    images_by_label = {}\n",
    "    for image, label in images:\n",
    "        if label not in images_by_label:\n",
    "            images_by_label[label] = []\n",
    "        images_by_label[label].append(image)\n",
    "\n",
    "    num_01 = min(len(images_by_label[0]), len(images_by_label[1]))\n",
    "    num_23 = min(len(images_by_label[2]), len(images_by_label[3]))\n",
    "    num_45 = min(len(images_by_label[4]), len(images_by_label[5]))\n",
    "    num_67 = min(len(images_by_label[6]), len(images_by_label[7]))\n",
    "    num_89 = min(len(images_by_label[8]), len(images_by_label[9]))\n",
    "\n",
    "    start_index = 0\n",
    "    for i in range(num_01):\n",
    "        images_by_label[0][i].save(os.path.join(path_A, f'{start_index+i}.png'))\n",
    "        images_by_label[1][i].save(os.path.join(path_B, f'{start_index+i}.png'))\n",
    "    start_index += num_01\n",
    "    for i in range(num_23):\n",
    "        images_by_label[2][i].save(os.path.join(path_A, f'{start_index+i}.png'))\n",
    "        images_by_label[3][i].save(os.path.join(path_B, f'{start_index+i}.png'))\n",
    "    start_index += num_23\n",
    "    for i in range(num_45):\n",
    "        images_by_label[4][i].save(os.path.join(path_A, f'{start_index+i}.png'))\n",
    "        images_by_label[5][i].save(os.path.join(path_B, f'{start_index+i}.png'))\n",
    "    start_index += num_45\n",
    "    for i in range(num_67):\n",
    "        images_by_label[6][i].save(os.path.join(path_A, f'{start_index+i}.png'))\n",
    "        images_by_label[7][i].save(os.path.join(path_B, f'{start_index+i}.png'))\n",
    "    start_index += num_67\n",
    "    for i in range(num_89):\n",
    "        images_by_label[8][i].save(os.path.join(path_A, f'{start_index+i}.png'))\n",
    "        images_by_label[9][i].save(os.path.join(path_B, f'{start_index+i}.png'))\n",
    "\n",
    "save_images(train_dataset, 'datasets/mnist/A/train/', 'datasets/mnist/B/train/')\n",
    "save_images(val_dataset, 'datasets/mnist/A/val/', 'datasets/mnist/B/val/')\n",
    "save_images(test_dataset, 'datasets/mnist/A/test/', 'datasets/mnist/B/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_A] =  datasets/mnist/A\n",
      "[fold_B] =  datasets/mnist/B\n",
      "[fold_AB] =  datasets/mnist/AB\n",
      "[num_imgs] =  1000000\n",
      "[use_AB] =  False\n",
      "[no_multiprocessing] =  False\n",
      "split = test, use 4814/4814 images\n",
      "split = test, number of images = 4814\n",
      "split = train, use 24133/24133 images\n",
      "split = train, number of images = 24133\n",
      "split = val, use 4904/4904 images\n",
      "split = val, number of images = 4904\n"
     ]
    }
   ],
   "source": [
    "!python datasets/combine_A_and_B.py --fold_A datasets/mnist/A --fold_B datasets/mnist/B --fold_AB datasets/mnist/AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/mnist/AB           \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: -1                            \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: mnist_pix2pix                 \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 24133\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints/mnist_pix2pix/web...\n",
      "/Users/kevinbeaulieu/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 100, time: 1.082, data: 8.620) G_GAN: 4.691 G_L1: 28.449 D_real: 0.011 D_fake: 0.011 \n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/mnist/AB --name mnist_pix2pix --model pix2pix --display_id -1 --gpu_ids -1 --save_latest_freq 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mey7o6j-0368"
   },
   "outputs": [],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot ./datasets/mnist --model pix2pix --name mnist_trained --use_wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/mnist_trained/test_latest/images/100_fake_B.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/mnist_trained/test_latest/images/100_real_A.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErK5OC1j1LH4"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/mnist_trained/test_latest/images/100_real_B.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pix2pix",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
